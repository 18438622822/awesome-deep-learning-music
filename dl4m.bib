@inproceedings{Leglaive2015,
title={Singing voice detection with deep recurrent neural networks},
author={Leglaive, Simon and Hennequin, Romain and Badeau, Roland},
booktitle={ICASSP},
pages={121--125},
year={2015},
organization={IEEE},
url={https://hal-imt.archives-ouvertes.fr/hal-01110035/},
task={SVD}
}
@inproceedings{Sigtia2015,
title={A hybrid recurrent neural network for music transcription},
author={Sigtia, Siddharth and Benetos, Emmanouil and Boulanger-Lewandowski, Nicolas and Weyde, Tillman and Garcez, Artur S d'Avila and Dixon, Simon},
booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},
pages={2061--2065},
year={2015},
organization={IEEE},
url={https://arxiv.org/pdf/1411.1623.pdf},
archi={RNN}
}
@inproceedings{Li2016,
title={A deep bidirectional long short-term memory based multi-scale approach for music dynamic emotion prediction},
author={Li, Xinxing and Xianyu, Haishu and Tian, Jiashen and Chen, Wenxiao and Meng, Fanhang and Xu, Mingxing and Cai, Lianhong},
booktitle={ICASSP},
pages={544--548},
year={2016},
organization={IEEE},
url={http://ieeexplore.ieee.org/document/7471734/},
archi={RNN & BILSTM & ELM},
task={MER}
}
@inproceedings{Su2016,
title={Convolutional neural network for robust pitch determination},
author={Su, Hong and Zhang, Hui and Zhang, Xueliang and Gao, Guanglai},
booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on},
pages={579--583},
year={2016},
organization={IEEE},
url={http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202016/pdfs/0000579.pdf},
archi={CNN & MLP}
}
@inproceedings{Holzapfel2016,
title={Bayesian meter tracking on learned signal representations},
author={Holzapfel, Andre and Grill, Thomas},
booktitle={ISMIR},
pages={262--268},
year={2016},
url={http://www.rhythmos.org/MMILab-Andre_files/ISMIR2016_CNNDBNbeats_camready.pdf},
archi={CNN},
task={Beat and backbeat detection}
}
@inproceedings{Schluter2016,
title={Learning to pinpoint singing voice from weakly labeled examples},
author={Schlüter, Jan},
booktitle={ISMIR},
pages={44--50},
year={2016},
url={http://www.ofai.at/~jan.schlueter/pubs/2016_ismir.pdf},
archi={CNN},
input={STFT}
}
@article{Li2015,
title={Automatic Instrument Recognition in Polyphonic Music Using Convolutional Neural Networks},
author={Li, Peter and Qian, Jiyuan and Wang, Tian},
journal={arXiv preprint arXiv:1511.05520},
year={2015},
url={https://arxiv.org/pdf/1511.05520.pdf},
task={Instrument recognition},
dataset={MedleyDB},
loss={Cross-entropy},
input={1D Freq Raw audio}
}
@article{Choi2015,
title={AURALISATION OF DEEP CONVOLUTIONAL NEURAL NETWORKS: LISTENING TO LEARNED FEATURES},
author={Choi, Keunwoo and Fazekas, George and Sandler, Mark and Kim, Jeonghee},
booktitle={ISMIR},
year={2015},
url={http://ismir2015.uma.es/LBD/LBD24.pdf},
task={Genre classification},
dataset={Inhouse},
input={STFT}
}
@article{Park2015a,
title={MUSIC-NOISE SEGMENTATION IN SPECTROTEMPORAL DOMAIN USING CONVOLUTIONAL NEURAL NETWORKS},
author={Park, Taejin and Lee, Taejin},
booktitle={ISMIR},
url={http://ismir2015.uma.es/LBD/LBD27.pdf},
loss={Cross-entropy},
year={2015},
task={Music/Noise segmentation},
input={2D}
}
@article{Zhang2015,
title={A Deep Neural Network for Modeling Music},
author={Zhang, Pengjing and Zheng, Xiaoqing and Zhang, Wenqiang and Li, Siyan and Qian, Sheng and He, Wenqi and Zhang, Shangtong and Wang, Ziyuan},
year={2015},
url={https://www.researchgate.net/profile/Xiaoqing_Zheng3/publication/275347034_A_Deep_Neural_Network_for_Modeling_Music/links/5539d2060cf2239f4e7dad0d/A-Deep-Neural-Network-for-Modeling-Music.pdf},
archi={CNN},
task={MGR}
}
@article{Park2015b,
title={Musical instrument sound classification with deep convolutional neural network using feature fusion approach},
author={Park, Taejin and Lee, Taejin},
journal={arXiv preprint arXiv:1512.07370},
year={2015},
url={https://arxiv.org/ftp/arxiv/papers/1512/1512.07370.pdf},
task={Instrument classification},
dataset={UIOWA MIS}
}
@article{Simpson2015,
title={Deep Karaoke: Extracting Vocals from Musical Mixtures Using a Convolutional Deep Neural Network},
author={Simpson, Andrew JR and Roma, Gerard and Plumbley, Mark D},
journal={arXiv preprint arXiv:1504.04658},
year={2015},
url={https://link.springer.com/chapter/10.1007/978-3-319-22482-4_50},
task={Source Separation},
input={STFT},
dataset={MedleyDB}
}
@article{Sigtia2015,
title={An End-to-End Neural Network for Polyphonic Music Transcription},
author={Sigtia, Siddharth and Benetos, Emmanouil and Dixon, Simon},
journal={arXiv preprint arXiv:1508.01774},
year={2015},
url={https://arxiv.org/pdf/1508.01774.pdf},
input={CQT},
task={Transcription}
}
@inproceedings{Grill2015,
title={Music Boundary Detection Using Neural Networks on Spectrograms and Self-Similarity Lag Matrices},
author={Grill, Thomas and Schlüter, Jan},
booktitle={EUSPICO},
address={Nice, France},
year={2015},
url={http://www.ofai.at/~jan.schlueter/pubs/2015_eusipco.pdf},
input={STFT},
task={Boundary detection},
dataset={SALAMI}
}
@inproceedings{Schluter2014,
title={Improved musical onset detection with convolutional neural networks},
author={Schluter, Jan and Bock, Sebastian},
booktitle={ICASSP},
pages={6979--6983},
year={2014},
organization={IEEE},
url={http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7029-schluter.pdf},
archi={CNN},
task={Onset Detection},
dataset={Inhouse},
input={Mel-spectrogram}
}
@inproceedings{Dieleman2014,
title={End-to-end learning for music audio},
author={Dieleman, Sander and Schrauwen, Benjamin},
booktitle={ICASSP},
pages={6964--6968},
year={2014},
organization={IEEE},
url={http://ieeexplore.ieee.org/abstract/document/6854950/},
archi={CNN},
task={MGR},
dataset={Magnatagatune},
input={Raw & Mel-spectrogram}
}
@inproceedings{Zhang2014,
title={A deep representation for invariance and music classification},
author={Zhang, Chiyuan and Evangelopoulos, Georgios and Voinea, Stephen and Rosasco, Lorenzo and Poggio, Tomaso},
booktitle={ICASSP},
pages={6984--6988},
year={2014},
organization={IEEE},
url={http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7034-zhang.pdf},
task={MGR},
dataset={GTzan},
archi={CNN}
}
@inproceedings{Ullrich2014,
title={Boundary Detection in Music Structure Analysis using Convolutional Neural Networks},
author={Ullrich, Karen and Schlüter, Jan and Grill, Thomas},
booktitle={ISMIR},
address={Taipei, Taiwan},
year={2014},
url={https://dav.grrrr.org/public/pub/ullrich_schlueter_grill-2014-ismir.pdf},
loss={Cross-entropy},
task={Boundary detection},
input={Mel-spectrogram},
dataset={SALAMI}
}
@inproceedings{Humphrey2014,
title={From music audio to chord tablature: Teaching deep convolutional networks toplay guitar},
author={Humphrey, Eric J and Bello, Juan P},
booktitle={ICASSP},
pages={6974--6978},
year={2014},
organization={IEEE},
url={http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7024-humphrey.pdf},
input={CQT},
task={Chord Recognition},
dataset={Beatles & RWC Pop & US Pop}
}
@article{Gwardys2014,
title={Deep Image Features in Music Information Retrieval},
author={Gwardys, Grzegorz and Grzywczak, Daniel},
journal={International Journal of Electronics and Telecommunications},
volume={60},
number={4},
pages={321--326},
year={2014},
url={https://www.degruyter.com/downloadpdf/j/eletel.2014.60.issue-4/eletel-2014-0042/eletel-2014-0042.pdf},
dataset={GTzan}
}
@inproceedings{Oord2013,
title={Deep content-based music recommendation},
author={Van den Oord, Aaron and Dieleman, Sander and Schrauwen, Benjamin},
booktitle={NIPS},
pages={2643--2651},
year={2013},
url={http://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf},
input={MFCC & Mel-Spectro},
dataset={MSD}
}
@inproceedings{Dieleman2013,
title={Multiscale Approaches To Music Audio Feature Learning.},
author={Dieleman, Sander and Schrauwen, Benjamin},
booktitle={ISMIR},
pages={3--8},
year={2013},
url={http://ismir2013.ismir.net/wp-content/uploads/2013/09/69_Paper.pdf},
input={Mel-spectrogram},
loss={cross-entropy},
dataset={Magnatagatune}
}
@inproceedings{Schluter2013,
title={Musical onset detection with convolutional neural networks},
author={Schlüter, Jan and Böck, Sebastian},
booktitle={International Workshop on Machine Learning and Music},
address={Prague, Czech Republic},
input={Mel-spectrogram},
loss={cross-entropy},
year={2013},
url={http://phenicx.upf.edu/system/files/publications/Schlueter_MML13.pdf}
}
@inproceedings{Nakashika2012,
title={Local-feature-map Integration Using Convolutional Neural Networks for Music Genre Classification},
author={Nakashika, Toru and Garcia, Christophe and Takiguchi, Tetsuya and De Lyon, Insa},
booktitle={INTERSPEECH},
year={2012},
url={http://liris.cnrs.fr/Documents/Liris-5602.pdf},
task={MGR},
dataset={GTzan},
input={GLCM}
}
@inproceedings{Wulfing2012,
title={Unsupervised Learning of Local Features for Music Classification.},
author={Wülfing, Jan and Riedmiller, Martin},
booktitle={ISMIR},
pages={139--144},
year={2012},
url={http://www.ismir2012.ismir.net/event/papers/139_ISMIR_2012.pdf},
input={CQT},
dataset={GTzan}
}
@inproceedings{Humphrey2012,
title={Rethinking automatic chord recognition with convolutional neural networks},
author={Humphrey, Eric J and Bello, Juan P.},
booktitle={ICMLA},
volume={2},
pages={357--362},
year={2012},
organization={IEEE},
url={http://ieeexplore.ieee.org/document/6406762/},
loss={Cross-entropy},
task={Chord recognition},
dataset={Beatles dataset & RWC Pop & US Pop},
archi={CNN}
}
@inproceedings{Li2010b,
title={Automatic musical pattern feature extraction using convolutional neural network},
author={Li, Tom LH and Chan, Antoni B and Chun, A},
booktitle={Int. Conf. Data Mining and Applications},
year={2010},
url={https://www.researchgate.net/profile/Antoni_Chan2/publication/44260643_Automatic_Musical_Pattern_Feature_Extraction_Using_Convolutional_Neural_Network/links/02e7e523dac6bb86b0000000.pdf},
input={MFCC},
task={MGR},
dataset={GTzan}
}
@phdthesis{Li2010a,
title={Audio musical genre classification using convolutional neural networks and pitch and tempo transformations},
author={Li, Lihua},
year={2010},
publisher={City University of Hong Kong},
url={http://lbms03.cityu.edu.hk/theses/c_ftt/mphil-cs-b39478026f.pdf},
input={MFCC},
dataset={GTzan}
}
@inproceedings{Lee2009,
title={Unsupervised feature learning for audio classification using convolutional deep belief networks},
author={Lee, Honglak and Pham, Peter and Largman, Yan and Ng, Andrew Y},
booktitle={Advances in neural information processing systems},
pages={1096--1104},
year={2009},
url={http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for-audio-classification-using-convolutional-deep-belief-networks.pdf},
archi={CDBN},
task={Speaker gender recognition},
dataset={TIMIT}
}
@inproceedings{Durand2015,
title={Downbeat tracking with multiple features and deep neural networks},
author={Durand, Simon and Bello, Juan P and David, Bertrand and Richard, Gaël},
booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},
pages={409--413},
year={2015},
organization={IEEE},
url={http://perso.telecom-paristech.fr/~grichard/Publications/2015-durand-icassp.pdf}
}
@inproceedings{Uhlich2015,
title={Deep neural network based instrument extraction from music},
author={Uhlich, Stefan and Giron, Franck and Mitsufuji, Yuki},
booktitle={ICASSP},
pages={2135--2139},
year={2015},
organization={IEEE},
url={https://www.researchgate.net/profile/Stefan_Uhlich/publication/282001406_Deep_neural_network_based_instrument_extraction_from_music/links/5600eeda08ae07629e52b397/Deep-neural-network-based-instrument-extraction-from-music.pdf},
task={Source separation},
input={STFT}
}
@inproceedings{Deng2016,
title={Automatic chord estimation on seventhsbass chord vocabulary using deep neural network},
author={Deng, Junqi and Kwok, Yu-Kwong},
booktitle={ICASSP},
pages={261--265},
year={2016},
organization={IEEE},
url={http://ieeexplore.ieee.org/abstract/document/7471677/},
task={Chord recognition}
}
@article{Korzeniowski2016,
title={Feature learning for chord recognition: the deep chroma extractor},
author={Korzeniowski, Filip and Widmer, Gerhard},
journal={arXiv preprint arXiv:1612.05065},
year={2016},
url={https://arxiv.org/pdf/1612.05065.pdf},
task={Chord recognition}
}
@article{Jeong2016,
Author = {Jeong, Il-Young and Lee, Kyogu},
Journal = {ISMIR},
Title = {Learning temporal features using a deep neural network and its application to music genre classification},
Year = {2016},
url={https://www.researchgate.net/profile/Il_Young_Jeong/publication/305683876_Learning_temporal_features_using_a_deep_neural_network_and_its_application_to_music_genre_classification/links/5799a27c08aec89db7bb9f92.pdf},
input={STFT & Cepstrum}
}
@article{Kelz2016,
title={On the Potential of Simple Framewise Approaches to Piano Transcription},
author={Kelz, Rainer and Dorfer, Matthias and Korzeniowski, Filip and Böck, Sebastian and Arzt, Andreas and Widmer, Gerhard},
journal={arXiv preprint arXiv:1612.05153},
year={2016},
url={https://arxiv.org/pdf/1612.05153.pdf},
archi={DNN & ConvNet}
}
@inproceedings{Rigaud2016,
title={Singing Voice Melody Transcription using Deep Neural Networks},
author={Rigaud, Fran{\c{c}}ois and Radenen, Mathieu},
booktitle={Proceedings of the International Conference on Music Information Retrieval (ISMIR). New York},
pages={737--743},
year={2016},
url={https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/07/163_Paper.pdf},
archi={DNN & RNN-LSTM},
task={f0 & VAD}
}
@inproceedings{Xu2017,
author={Yong Xu and Qiuqiang Kong and Qiang Huang and Wenwu Wang and Mark D. Plumbley},
title={Attention and Localization Based on a Deep Convolutional Recurrent Model for Weakly Supervised Audio Tagging},
year={2017},
booktitle={INTERSPEECH},
pages={3083--3087},
doi={10.21437/Interspeech.2017-486},
url={http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0486.PDF},
code={https://github.com/yongxuUSTC/att_loc_cgrnn},
task={DCASE},
archi={CRNN},
link={https://sites.google.com/view/xuyong/demos/attention_model}
}
@conference {Chandna2017,
title = {Monoaural Audio Source Separation Using Deep Convolutional Neural Networks},
booktitle = {International Conference on Latent Variable Analysis and Signal Separation (LVA ICA)},
year = {2017},
month = {Feb.},
keywords = {deep learning, neural networks, source separation},
url={http://mtg.upf.edu/system/files/publications/monoaural-audio-source_0.pdf},
archi={CNN},
task={Source separation},
dataset={DSD100},
code={https://github.com/MTG/DeepConvSep},
author = {Pritish Chandna and Marius Miron and Jordi Janer and Emilia Gomez}
}
@INPROCEEDINGS{Lewis1988,
author={Lewis, J. P.},
booktitle={IEEE International Conference on Neural Networks},
title={Creation by refinement: a creativity paradigm for gradient descent learning networks},
year={1988},
volume={2},
pages={229-233},
abstract={The author describes a paradigm for creating novel examples from the class of patterns recognized by a trained gradient-descent associative learning network. The paradigm consists of a learning phase, in which the network learns to identify patterns of the desired class, followed by a simple synthesis algorithm, in which a haphazard 'creation' is refined by a gradient-descent search complementary to the one used in learning. This paradigm is an alternative to one in which novel patterns are obtained by applying novel inputs to a learned mapping, and can be used for creative problems, such as music composition, which are not described by an input-output mapping. A simple simulation is shown in which a back-propagation network learns to judge simple patterns representing musical motifs, and then creates similar motifs.<>},
keywords={content-addressable storage;learning systems;neural nets;associative learning network;back-propagation network;creativity paradigm;gradient descent learning networks;gradient-descent search;learning phase;music composition;musical motifs;pattern recognition;refinement;synthesis algorithm;Associative memories;Learning systems;Neural networks},
doi={10.1109/ICNN.1988.23933},
ISSN={},
month={July}
}
@article{Laden1989,
ISSN = {01489267, 15315169},
URL = {http://www.jstor.org/stable/3679550},
author = {Laden, Bernice and Keefe, Douglas H.},
journal = {Computer Music Journal},
number = {4},
pages = {12-26},
publisher = {The MIT Press},
title = {The Representation of Pitch in a Neural Net Model of Chord Classification},
volume = {13},
year = {1989},
task={Chord classification}
}
@book{Griffith1999,
title={Musical networks: Parallel distributed perception and performance},
author={Griffith, Niall and Todd, Peter M.},
year={1999},
publisher={MIT Press},
url={https://s3.amazonaws.com/academia.edu.documents/3551783/10.1.1.39.6248.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1507055806&Signature=5mGzQc7bvJgUZYfXOmCX8eeNQOs%3D&response-content-disposition=inline%3B%20filename%3DMusical_networks_Parallel_distributed_pe.pdf}
}
@inproceedings{Franklin2001,
title={Multi-phase learning for jazz improvisation and interaction},
author={Franklin, Judy A},
booktitle={Biennial Symposium for Arts and Technology},
year={2001},
url={http://www.cs.smith.edu/~jfrankli/papers/CtColl01.pdf},
archi={RNN},
task={Composition}
}
@inproceedings{Pons2016,
author = {Pons, Jordi and Lidy, Thomas and Serra, Xavier},
title = {Experimenting with Musically Motivated Convolutional Neural Networks},
booktitle = {CBMI},
month = {June 15-17},
year = {2016},
researchfields = {MIR},
doi = {10.1109/CBMI.2016.7500246},
isbn = {978-1-4673-8695-1},
url = {http://jordipons.me/media/CBMI16.pdf},
pdf = {http://publik.tuwien.ac.at/files/publik_255991.pdf},
address = {Bucharest, Romania},
code={https://github.com/jordipons/},
dataset={Ballroom}
}
@article{Todd1989,
ISSN = {01489267, 15315169},
URL = {http://www.jstor.org/stable/3679551},
author = {Todd, Peter M.},
journal = {Computer Music Journal},
number = {4},
pages = {27-43},
publisher = {The MIT Press},
title = {A Connectionist Approach to Algorithmic Composition},
volume = {13},
year = {1989}
}
@inproceedings{Todd1988,
title={A sequential network design for musical applications},
author={Todd, Peter},
booktitle={Connectionist Models Summer School},
pages={76--84},
year={1988}
}
@inproceedings{Lewis1989,
title={Algorithms for music composition by neural nets: improved CBR paradigms},
author={Lewis, J. P.},
year={1989},
publisher={Ann Arbor, MI: Michigan Publishing, University of Michigan Library},
booktitle={ICMC},
url={https://quod.lib.umich.edu/cgi/p/pod/dod-idx/algorithms-for-music-composition.pdf?c=icmc;idno=bbp2372.1989.044;format=pdf},
task={Composition}
}
@article{Mozer1999,
title={Neural network music composition by prediction: Exploring the benefits of psychoacoustic constraints and multi-scale processing},
journal={Connection Science},
volume={6},
number={2-3},
pages={247--280},
year={1994},
publisher={Taylor \& Francis},
author={Mozer, Michael C.},
task={Composition},
url={http://www-labs.iro.umontreal.ca/~pift6080/H09/documents/papers/mozer-music.pdf}
}
@inproceedings{Matityaho1995,
title={Neural network based model for classification of music type},
author={Matityaho, Benyamin and Furst, Miriam},
booktitle={Convention of Electrical and Electronics Engineers},
pages={4--3},
year={1995},
organization={IEEE},
address = {Israel},
url={http://ieeexplore.ieee.org/abstract/document/514161/},
task={MGR}
}
@inproceedings{Dannenberg1997,
title={A machine learning approach to musical style recognition},
author={Dannenberg, Roger B and Thom, Belinda and Watson, David},
year={1997},
publisher={University of Michigan},
booktitle={ICMC},
url={http://repository.cmu.edu/cgi/viewcontent.cgi?article=1496&context=compsci},
task={MSR}
}
@article{Bammer2017,
  title={Gabor frames and deep scattering networks in audio processing},
  author={Bammer, Roswitha and Doerfler, Monika},
  journal={arXiv preprint arXiv:1706.08818},
  year={2017},
  url={https://arxiv.org/pdf/1706.08818.pdf}
}
@inproceedings{Bazzica2017,
  title={Vision-based Detection of Acoustic Timed Events: a Case Study on Clarinet Note Onsets},
  author={Bazzica, A and van Gemert, JC and Liem, CCS and Hanjalic, A},
  booktitle={IWDLM},
  year={2017},
  url={http://dorienherremans.com/dlm2017/papers/bazzica2017clarinet.pdf},
  archi={CNN},
  task={Note-onset detection},
  dataset={http://mmc.tudelft.nl/users/alessio-bazzica#C4S-dataset}
}
@article{Briot2017,
  title={Deep Learning Techniques for Music Generation-A Survey},
  author={Briot, Jean-Pierre and Hadjeres, Gaëtan and Pachet, François},
  journal={arXiv preprint arXiv:1709.01620},
  year={2017},
  url={https://arxiv.org/pdf/1709.01620.pdf}
}
@article{Cangea2017,
  title={XFlow: 1D-2D Cross-modal Deep Neural Networks for Audiovisual Classification},
  author={Cangea, C{\u{a}}t{\u{a}}lina and Veli{\v{c}}kovi{\'c}, Petar and Li{\`o}, Pietro},
  journal={arXiv preprint arXiv:1709.00572},
  year={2017},
  url={https://arxiv.org/pdf/1709.00572.pdf}
}
@inproceedings{Cella2017,
  title={Machine listening intelligence},
  author={Cella, Carmine-Emanuele},
  booktitle={IWDLM},
  year={2017},
  url={http://dorienherremans.com/dlm2017/papers/cella2017mli.pdf}
}
@inproceedings{Chen2017,
  title={Deep multimodal network for multi-label classification},
  author={Chen, Tanfang and Wang, Shangfei and Chen, Shiyu},
  booktitle={ICME},
  pages={955--960},
  year={2017},
  organization={IEEE},
  url={http://ieeexplore.ieee.org/abstract/document/8019322/}
}
@article{Choi2017a,
  title={A Tutorial on Deep Learning for Music Information Retrieval},
  author={Choi, Keunwoo and Fazekas, Gy{\"o}rgy and Cho, Kyunghyun and Sandler, Mark},
  journal={arXiv preprint arXiv:1709.04396},
  year={2017},
  url={https://arxiv.org/pdf/1709.04396.pdf},
  code={https://github.com/keunwoochoi/dl4mir}
}
@article{Choi2017b,
  title={A Comparison on Audio Signal Preprocessing Methods for Deep Neural Networks on Music Tagging},
  author={Choi, Keunwoo and Fazekas, George and Cho, Kyunghyun and Sandler, Mark},
  journal={arXiv preprint arXiv:1709.01922},
  year={2017},
  url={https://arxiv.org/pdf/1709.01922.pdf},
  code={https://github.com/keunwoochoi/transfer_learning_music},
  task={MGR},
  dataset={MSD}
}
@inproceedings{Choi2017c,
  title={Transfer learning for music classification and regression tasks},
  author={Choi, Keunwoo and Fazekas, Gy{\"o}rgy and Sandler, Mark and Cho, Kyunghyun},
  booktitle={ISMIR},
  year={2017},
  url={https://arxiv.org/pdf/1703.09179v3.pdf},
  code={https://github.com/keunwoochoi/transfer_learning_music}
}
@inproceedings{Choi2017d,
  title={Convolutional recurrent neural networks for music classification},
  author={Choi, Keunwoo and Fazekas, Gy{\"o}rgy and Sandler, Mark and Cho, Kyunghyun},
  booktitle={ICASSP},
  pages={2392--2396},
  year={2017},
  organization={IEEE},
  url={http://ieeexplore.ieee.org/abstract/document/7952585/},
  code={https://github.com/keunwoochoi/icassp_2017},
  reproducible={Models & split sets only},
  archi={CRNN},
  task={MGR}
}
@article{Costa2017,
  title={An evaluation of Convolutional Neural Networks for music classification using spectrograms},
  author={Costa, Yandre MG and Oliveira, Luiz S and Silla, Carlos N},
  journal={Applied Soft Computing},
  volume={52},
  pages={28--38},
  year={2017},
  publisher={Elsevier},
  url={http://www.inf.ufpr.br/lesoliveira/download/ASOC2017.pdf},
  archi={CNN},
  dataset={LMD}
}
@article{Deng2017,
  title={Large Vocabulary Automatic Chord Estimation Using Deep Neural Nets: Design Framework, System Variations and Limitations},
  author={Deng, Junqi and Kwok, Yu-Kwong},
  journal={arXiv preprint arXiv:1709.07153},
  year={2017},
  url={https://arxiv.org/pdf/1709.07153.pdf}
}
@article{Doerfler2017,
  title={Basic Filters for Convolutional Neural Networks: Training or Design?},
  author={Doerfler, Monika and Grill, Thomas and Bammer, Roswitha and Flexer, Arthur},
  journal={arXiv preprint arXiv:1709.02291},
  year={2017},
  url={https://arxiv.org/pdf/1709.02291.pdf},
  task={CNN},
  input={Raw & Mel-spectrogram},
  task={SVD},
  dataset={Inhouse},
  optimizer={Adam},
  lr={0.001}
}
@inproceedings{Fan2017,
  title={Music Signal Processing Using Vector Product Neural Networks},
  author={Fan, Zhe-Cheng and Chan, TS and Yang, Yi-Hsuan and Jang, Jyh-Shing R},
  booktitle={IWDLM},
  year={2017},
  url={http://dorienherremans.com/dlm2017/papers/fan2017vector.pdf},
  archi={VPNN & DNN},
  task={SVS},
  dataset={iKala}
}
@inproceedings{geng2017transforming,
  title={Transforming Musical Signals through a Genre Classifying Convolutional Neural Network},
  booktitle={IWDLM},
  author={Geng, Shijia and Ren, Gang and Ogihara, Mitsunori},
  year={2017},
  url={http://dorienherremans.com/dlm2017/papers/geng2017genre.pdf},
  archi={CNN},
  task={Composition},
  dataset={https://sites.google.com/site/modificationofmusicsignals/audio-files}
}
@inproceedings{Gong2017,
  title={Audio to score matching by combining phonetic and duration information},
  author={Gong, Rong and Pons, Jordi and Serra, Xavier},
  booktitle={ISMIR},
  year={2017},
  url={https://arxiv.org/pdf/1707.03547.pdf},
  code={https://github.com/ronggong/jingjuSingingPhraseMatching/tree/v0.1.0}
}
@article{Hadjeres2017a,
  title={Interactive Music Generation with Positional Constraints using Anticipation-RNNs},
  author={Hadjeres, Gaëtan and Nielsen, Frank},
  journal={arXiv preprint arXiv:1709.06404},
  year={2017},
  url={https://arxiv.org/pdf/1709.06404.pdf},
  archi={ARNN},
  task={Composition}
}
@article{Hadjeres2017b,
  title={Deep rank-based transposition-invariant distances on musical sequences},
  author={Hadjeres, Gaëtan and Nielsen, Frank},
  journal={arXiv preprint arXiv:1709.00740},
  year={2017},
  url={https://arxiv.org/pdf/1709.00740.pdf}
}
@article{Hadjeres2017c,
  title={GLSR-VAE: Geodesic Latent Space Regularization for Variational AutoEncoder Architectures},
  author={Hadjeres, Gaëtan and Nielsen, Frank and Pachet, François},
  journal={arXiv preprint arXiv:1707.04588},
  year={2017},
  url={https://arxiv.org/pdf/1707.04588.pdf}
}
@inproceedings{Hadjeres2016d,
  title={DeepBach: a Steerable Model for Bach chorales generation},
  author={Hadjeres, Gaëtan and Pachet, François},
  booktitle={ICML},
  year={2016},
  url={https://arxiv.org/pdf/1612.01010.pdf},
  code={https://github.com/Ghadjeres/DeepBach}
}
@article{Han2017,
  title={Deep convolutional neural networks for predominant instrument recognition in polyphonic music},
  author={Han, Yoonchang and Kim, Jaehun and Lee, Kyogu and Han, Yoonchang and Kim, Jaehun and Lee, Kyogu},
  journal={IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)},
  volume={25},
  number={1},
  pages={208--221},
  year={2017},
  publisher={IEEE Press},
  url={http://dl.acm.org/citation.cfm?id=3068697},
  archi={CNN},
  task={Instrument recognition},
  dataset={IRMAS}
}
@inproceedings{Hershey2017,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={ICASSP},
  pages={131--135},
  year={2017},
  organization={IEEE},
  url={https://arxiv.org/pdf/1609.09430v2.pdf},
  archi={CNN}
}
@inproceedings{Hsu2017,
  title={DeepSheet: A sheet music generator based on deep learning},
  author={Hsu, Yu-Lun and Lin, Chi-Po and Lin, Bo-Chen and Kuo, Hsu-Chan and Cheng, Wen-Huang and Hu, Min-Chun},
  booktitle={IEEE_ICME},
  pages={285--290},
  year={2017},
  organization={IEEE},
  url={http://ieeexplore.ieee.org/abstract/document/8026272/},
  task={Composition}
}
@inproceedings{Hutchings2017,
  title={Talking Drums: Generating drum grooves with neural networks},
  author={Hutchings, P.},
  booktitle={IWDLM},
  year={2017},
  url={http://dorienherremans.com/dlm2017/papers/hutchings2017drums.pdf},
  archi={RNN},
  task={Composition}
}
@inproceedings{Jeon2017,
  title={Music Emotion Recognition via End-to-End Multimodal Neural Networks},
  author={Jeon, Byungsoo and Kim, Chanju and Kim, Adrian and Kim, Dongwon and Park, Jangyeon and Ha, Jung-Woo},
  url={http://ceur-ws.org/Vol-1905/recsys2017_poster18.pdf},
  task={MER},
  dataset={Inhouse},
  booktitle={RECSYS},
  archi={CNN}
}
@inproceedings{Koops2017,
  title={Chord Label Personalization through Deep Learning of Integrated Harmonic Interval-based Representations},
  author={Koops, Hendrik Vincent and de Haas, W Bas and Bransen, Jeroen and Volk, Anja},
  booktitle={IWDLM},
  year={2017},
  url={http://dorienherremans.com/dlm2017/papers/koops2017pers.pdf}
}
@article{Korzeniowski2017,
  title={End-to-End Musical Key Estimation Using a Convolutional Neural Network},
  author={Korzeniowski, Filip and Widmer, Gerhard},
  journal={arXiv preprint arXiv:1706.02921},
  year={2017},
  url={https://arxiv.org/pdf/1706.02921.pdf}
}
@inproceedings{Koutini2017,
  title={MediaEval 2017 AcousticBrainz Genre Task: Multilayer Perceptron Approach},
  author={Koutini, Khaled and Imenina, Alina and Dorfer, Matthias and Gruber, Alexander Rudolf and Schedl, Markus},
  booktitle={MediaEval},
  url={http://www.cp.jku.at/research/papers/Koutini_2017_mediaeval-acousticbrainz.pdf}
}
@inproceedings{Lee2017a,
  title={Sample-level Deep Convolutional Neural Networks for Music Auto-tagging Using Raw Waveforms},
  author={Lee, Jongpil and Park, Jiyoung and Kim, Keunhyoung Luke and Nam, Juhan},
  booktitle={SMC},
  year={2017},
  url={https://arxiv.org/pdf/1703.01789v2.pdf}
}
@article{Lee2017b,
  title={Multi-Level and Multi-Scale Feature Aggregation Using Pre-trained Convolutional Neural Networks for Music Auto-tagging},
  author={Lee, Jongpil and Nam, Juhan},
  journal={IEEE SIGNAL PROCESSING LETTERS},
  year={2017},
  url={https://arxiv.org/pdf/1703.01793v2.pdf}
}
@article{Lee2017c,
  title={Multi-Level and Multi-Scale Feature Aggregation Using Sample-level Deep Convolutional Neural Networks for Music Classification},
  author={Lee, Jongpil and Nam, Juhan},
  journal={arXiv preprint arXiv:1706.06810},
  year={2017},
  url={https://arxiv.org/pdf/1706.06810.pdf},
  code={https://github.com/jongpillee/musicTagging_MSD},
  dataset={MSD}
}
@inproceedings{Lim2017,
  title={Harmonic and Percussive Source Separation Using a Convolutional Auto Encoder},
  author={Lim, Wootaek and Lee, Taejin},
  booktitle={EUSIPCO},
  url={http://www.eurasip.org/Proceedings/Eusipco/Eusipco2017/papers/1570346835.pdf},
  task={Source separation},
  dataset={DSD100},
  archi={CNN}
}
@inproceedings{Miron2017a,
  title={Generating data to train convolutional neural networks for classical music source separation},
  author={Miron, Marius and Janer Mestres, Jordi and G{\'o}mez Guti{\'e}rrez, Emilia},
  booktitle={SMC},
  month={Jul.},
  address={Espoo, Finland},
  pages={227},
  year={2017},
  organization={Aalto University},
  url={https://www.researchgate.net/profile/Marius_Miron/publication/318322107_Generating_data_to_train_convolutional_neural_networks_for_classical_music_source_separation/links/59637cc3458515a3575b93c6/Generating-data-to-train-convolutional-neural-networks-for-classical-music-source-separation.pdf?_iepl%5BhomeFeedViewId%5D=WchoMnlUL1Hk9hBLVTeR8Amh&_iepl%5Bcontexts%5D%5B0%5D=pcfhf&_iepl%5BinteractionType%5D=publicationDownload&origin=publication_detail&ev=pub_int_prw_xdl&msrp=p3lQ8M4uZlb4TF5Hv9a2U3P2y4wW7ant5KWj4E5-OcD1Mg53p1ykTKHMG9_zVTB9n6mI8fvZOCL2Xhpru186pCEY-2ZxiYR-CB8_QvwHc1kUG-QE4SHdProR.LoJb2BDOiiQth3iR9xgZUxxCWEJgtTBF4whFrFa01OD49-3YYRxA0WQVN--zhtQU_7C2Pt0rKdwoFxT1pfxFvnKXSXmy2eT1Jpz-pw.U1QLoFO_Uc6aQVr2Nm2FcAi6BqAUfngH2Or5__6wegbCgVvTYoIGt22tmCkYbGTOQ_4PxBgt1LrvsFQiL0oMyogP8Yk8myTj0gs9jw.fGpkufGqAI4R2v8Hfe0ThcXL7M7yN2PuAlx974BGVn50SdUWvNhhIPWBD-zWTn8NKtVJx3XrjKXFrMgi9Cx7qGrNP8tBWpha6Srf6g},
  archi={CNN},
  task={Source separation},
  dataset={RWC & Bach10},
  code={https://github.com/MTG/DeepConvSep}
}

Monaural score-informed source separation for classical music using convolutional neural networks   Miron   2017    ISMIR   https://www.researchgate.net/profile/Marius_Miron/publication/318637038_Monaural_score-informed_source_separation_for_classical_music_using_convolutional_neural_networks/links/597327c6458515e26dfdb007/Monaural-score-informed-source-separation-for-classical-music-using-convolutional-neural-networks.pdf?_iepl%5BhomeFeedViewId%5D=WchoMnlUL1Hk9hBLVTeR8Amh&_iepl%5Bcontexts%5D%5B0%5D=pcfhf&_iepl%5BinteractionType%5D=publicationDownload&origin=publication_detail&ev=pub_int_prw_xdl&msrp=Hp6dDqMepEiRZ5E6WkreaqyjFkFkwMxPFoJvr14etVJsoKZBc5qb99fBnJjVUZrRHLFRhaXvNY9k1sMvYPOouuGbQP0YhEGm28zLw_55Zewu86WGnHck1Tqi.93HH2WqXfTedn6IaZRjjhQGYZVDHBz1X6nr4ABBgMAVv584gvGN3sW5IyBAY-4MBWf5DJFPBGm8zsaC2dKz8G-odZPfosWoXY0afAQ.KoCP2mO9l31lCER0oMZMZBrbuRGvb6ZzeBwHb88pL8AhMfJk03Hj1eLrohQIjPDETBj4hhqb0gniDGJgtZ9GnW64ZNjh9GbQDrIl5A.egNQTyC7t8P26zCQWrbEhf51Pxy2JRBZoTkH6SpRHHhRhFl1_AT_AT481lMcFI34-JbeRq-5oTQR7DpvAuw7iUIivd78ltuxpI9syg   https://github.com/MTG/DeepConvSep      CNN                     Source separation   Bach10      
Monaural score-informed source separation for classical music using convolutional neural networks   Miron   2017    ISMIR   https://www.researchgate.net/profile/Marius_Miron/publication/318637038_Monaural_score-informed_source_separation_for_classical_music_using_convolutional_neural_networks/links/597327c6458515e26dfdb007/Monaural-score-informed-source-separation-for-classical-music-using-convolutional-neural-networks.pdf?origin=publication_detail&ev=pub_int_prw_xdl&msrp=Xlvhp7_af0NtWzNjBDJMwVFZKXVR_wdy_LSzWeqrWPW_tzGn8rP1TzAOGjBsa5_aQv792tcOmiSt-dV_bV4F3ILb4fLgeUdXuVGe1VdfLfN0ir7Snqiibz4B.nlqiciBhaFRxXVKWmAZPoO8pWJboNtFtNTJMHipjYmAQFU-zpAG-rm1X_c4T8iUbzCIiZ6Pt9lcgkwFebf6I0AsV4c2X5pyeqUafcg.3gQ-LC6mPG47tnGNCPZb6ZvtZgGhK34UJBpBebt8sKK-b2grBaqp0oFOxPj1J70Jln1UVmV64O0qySfw_04TnVJysDd8eSoQf2T7rQ.jqs7NDRUVlKLwic8ZIqLf0CQfUVaebyBESVFo-ndM6yfTpUlJiEG1DV7jvQpYQl_tRnnfCpkyv8BXYq-U6Cub_Ys3BW5BqVMFdon3A  https://github.com/MTG/DeepConvSep      CNN                     Source separation           
A deep multimodal approach for cold-start music recommendation  Oramas  2017    DLRS    https://arxiv.org/pdf/1706.09739.pdf    https://github.com/sergiooramas/tartarus        CNN                     Recommendation  MSD     
Multi-label Music Genre Classification from Audio, Text, and Images using Deep Features Oramas  2017    ISMIR   https://arxiv.org/abs/1707.04916    https://github.com/sergiooramas/tartarus        CNN                     Genre   MSD     
Melody extraction and detection through LSTM-RNN with harmonic sum loss Park    2017    ICML    http://ieeexplore.ieee.org/abstract/document/7952660/                                               
Toward inverse control of physics-based sound synthesis Pfalz   2017    IWDLM   http://dorienherremans.com/dlm2017/papers/pfalz2017synthesis.pdf    No  No                                  https://www.cct.lsu.edu/~apfalz/inverse_control.html    
Score-informed syllable segmentation for a capella singing voice with convolutional neural networks Pons    2017    ISMIR   https://arxiv.org/pdf/1707.03544.pdf    https://github.com/ronggong/jingjuSyllabicSegmentaion/tree/v0.1.0                               Syllable segmentation           
Timbre analysis of music audio signals with convolutional neural networks   Pons    2017    EUSIPCO https://arxiv.org/pdf/1703.06697.pdf    https://github.com/jordipons/EUSIPCO2017        CNN                             https://github.com/ronggong/EUSIPCO2017 https://github.com/Veleslavia/EUSIPCO2017
Designing efficient architectures for modeling temporal features with convolutional neural networks Pons    2017        http://ieeexplore.ieee.org/document/7952601/    https://github.com/jordipons/ICASSP2017     CNN                     Genre   Ballroom        
Deep learning for event detection, sequence labelling and similarity estimation in music signals    Schlüter    2017    Thesis  http://ofai.at/~jan.schlueter/pubs/phd/phd.pdf  No  No                                      
Music feature maps with convolutional neural networks for music genre classification    Senac   2017    CBMI    https://www.researchgate.net/profile/Thomas_Pellegrini/publication/319326354_Music_Feature_Maps_with_Convolutional_Neural_Networks_for_Music_Genre_Classification/links/59ba5ae3458515bb9c4c6724/Music-Feature-Maps-with-Convolutional-Neural-Networks-for-Music-Genre-Classification.pdf?origin=publication_detail&ev=pub_int_prw_xdl&msrp=wzXuHZAa5zAnqEmErYyZwIRr2H0q01LnNEd4Wd7A15CQfdVLwdy98pmE-AdnrDvoc3-bVENSFrHt0yhaOiE2mQrYllVS9CJZOk-c9R0j_R1rbgcZugS6RtQ_.AUjPuJSF5P_DMngf-woH7W-7jdnQlbNQziR4_h6NnCHfR_zGcEa8vOyyOz5gx5nc4azqKTPQ5ZgGGLUxkLj1qCQLEQ5ThkhGlWHLyA.s6MBZE20-EO_RjRGCOCV4wk0WSFdN56Aloiraxz9hKCbJwRM2Et27RHVUA8jj9H8qvXIB6f7zSIrQgjXGrL2yCpyQlLffuf57rzSwg.KMMXbZrHsihV8DJM53xkHAWf3VebCJESi4KU4btNv9nQsyK2KnkhSQaTILKv0DSZY3c70a61LzywCBuoHtIhVOFhW5hVZN2n5O9uKQ   No  No  CNN         8           Genre   GTzan   Compare input CNN spectro & features audio  
Automatic drum transcription for polyphonic recordings using soft attention mechanisms and convolutional neural networks    Southall    2017    ISMIR   http://www.ryanstables.co.uk/docs/ISMIR2017CamReady.pdf https://github.com/CarlSouthall/ADTLib      CNN & BRNN                      ADT IDMT-SMT-Drums dataset  Polyphonic recordings & Soft Attention & Peripheral Connection  
Taking the models back to music practice: evaluating generative transcription models built using deep learning  Sturm   2017    JCMS    http://jcms.org.uk/issues/Vol2Issue1/taking-models-back-to-music-practice/Taking%20the%20Models%20back%20to%20Music%20Practice:%20Evaluating%20Generative%20Transcription%20Models%20built%20using%20Deep%20Learning.pdf    https://github.com/IraKorshunova/folk-rnn                                           
Convolutional methods for music analysis    Velarde 2017    Thesis  http://vbn.aau.dk/files/260308151/PHD_Gissel_Velarde_E_pdf.pdf                                              
Extending temporal feature integration for semantic audio analysis  Vrysis  2017        http://www.aes.org/e-lib/browse.cfm?elib=18682  No  No  ANN                                 
A two-stage approach to note-level transcription of a specific piano    Wang    2017    AS_SMC  http://www.mdpi.com/2076-3417/7/9/901/htm   No  No                          Transcription           
Recognition and retrieval of sound events using sparse coding convolutional neural network  Wang    2017    IEEE_ICME   http://ieeexplore.ieee.org/abstract/document/8019552/           CNN                     Sound event recognition         
Audio spectrogram representations for processing with convolutional neural networks Wyse    2017    IWDLM   http://dorienherremans.com/dlm2017/papers/wyse2017spect.pdf No  No  CNN         2                   http://lonce.org/research/audioST/  
Surrey-CVSSP system for DCASE2017 challenge task4   Xu  2017    DCASE   https://www.cs.tut.fi/sgn/arg/dcase2017/documents/challenge_technical_reports/DCASE2017_Xu_146.pdf  https://github.com/yongxuUSTC/dcase2017_task4_cvssp                             DCASE           
A study on LSTM networks for polyphonic music sequence modelling    Ycart   2017        https://qmro.qmul.ac.uk/xmlui/handle/123456789/24946    http://www.eecs.qmul.ac.uk/~ay304/code/ismir17  TODO    LSTM-RNN            1           polyphonic music sequence modelling Synthetic MIDI & Piano-midi.de  data augmentation = pitch shift 
An efficient approach for segmentation, feature extraction and classification of audio signals  Arumugam    2016        http://file.scirp.org/pdf/CS_2016042615054817.pdf   No  No  PNN                                 
Text-based LSTM networks for automatic music composition    Choi    2016    CSMC    https://drive.google.com/file/d/0B1OooSxEtl0FcG9MYnY2Ylh5c0U/view   No  No                          Composition         
Towards playlist generation algorithms using rnns trained on within-track transitions   Choi    2016        https://arxiv.org/pdf/1606.02096.pdf    No  No  RNN                     Playlist generation         
Automatic tagging using deep convolutional neural networks  Choi    2016        https://arxiv.org/pdf/1606.00298.pdf    No  No  FCN                     Genre           
Robust downbeat tracking using an ensemble of convolutional networks    Durand  2016        http://ieeexplore.ieee.org/abstract/document/7728057/           CNN                     Downbeat detection      Combine multiple CNN on multiple features   
Deep learning for music Huang   2016    arXiv   https://arxiv.org/pdf/1606.04930.pdf            LSTM-RNN            2           Composition Bach Corpus https://www.researchgate.net/publication/303993170_Deep_Learning_for_Music  
A fully convolutional deep auditory model for musical chord recognition Korzeniowski    2016    IEEE_MLSP   https://www.researchgate.net/profile/Filip_Korzeniowski/publication/305590295_A_Fully_Convolutional_Deep_Auditory_Model_for_Musical_Chord_Recognition/links/579486ba08aed51475cc6958/A-Fully-Convolutional-Deep-Auditory-Model-for-Musical-Chord-Recognition.pdf?_iepl%5BhomeFeedViewId%5D=HTzFFmKPia2YminQ4psHT5at&_iepl%5Bcontexts%5D%5B0%5D=pcfhf&_iepl%5BinteractionType%5D=publicationDownload&origin=publication_detail&ev=pub_int_prw_xdl&msrp=Dz_6LKHzYcPyP-LmgZPF-m63ayZ6k0entFEntooiu_e32zfETNQXKPQSTFOI87NONIIQuUQdnUtwORdomTXfteTrb09KiAIdDtBJnw_02P6JeRr5zu2eyaCG.2Uxsi_eENxtbYL39lvorIK8LofRYhkgpUHzpzmVzkIEiyHc0wUY87rEa4PH1qbXi4k4RyagHUsA2IsZtewnprglORjx2v9Cwbk9ZfQ.cd67BaqtHul_hE6SX6vUFKuldz81aH6dWq-cYMkq5vQKCHcvB8l9zgeM694Efb_r2wBB5GT9idt3OLeME0UxVHI6ROxamgK3LMNlSw.JtZXAo9HhR9t-8Wl3gxJgnoM4--rtmDEUDbXSWezbFyU-CoB_nyfxbRQ4kdoN4-5aJ3Tgx4YHdikicqAhc_cezB2ZntjxkB4rEDx1A No  No                          Chord recognition           
Event localization in music auto-tagging    Liu 2016        http://mac.citi.sinica.edu.tw/~yang/pub/liu16mm.pdf https://github.com/ciaua/clip2frame     CNN                                 
Deep convolutional networks on the pitch spiral for musical instrument recognition  Lostanlen   2016        https://github.com/lostanlen/ismir2016/blob/master/paper/lostanlen_ismir2016.pdf                                                
Robust audio event recognition with 1-max pooling convolutional neural networks Phan    2016        https://arxiv.org/pdf/1604.06338.pdf    No  No  CNN                     audio event recognition RWC compare MFCC & deep learning    
Singing voice separation using deep neural networks and F0 estimation   Roma    2016    MIREX   http://www.music-ir.org/mirex/abstracts/2016/RSGP1.pdf  http://cvssp.org/projects/maruss/mirex2016/     DNN         3       No  SVS iKala   F0 estimation   
Note onset detection in musical signals via neural-network-based multi-ODF fusion   Stasiak 2016        https://www.degruyter.com/downloadpdf/j/amcs.2016.26.issue-1/amcs-2016-0014/amcs-2016-0014.pdf  No  No  NNMODFF                     Onset Detection Daudet2004  not input spectro but onset activation  
Music transcription modelling and composition using deep learning   Sturm   2016    CSMC    https://drive.google.com/file/d/0B1OooSxEtl0FcTBiOGdvSTBmWnc/view   https://github.com/IraKorshunova/folk-rnn                                           
Deep convolutional neural networks and data augmentation for acoustic event detection   Takahashi   2016        https://arxiv.org/pdf/1604.07160.pdf    No  No  CNN         9           Acoustic Event Detection    FreeSound   Data augmentation = mixing  
Unsupervised feature learning based on deep models for environmental audio tagging  Xu  2016        https://arxiv.org/pdf/1607.03681.pdf                                                
Classification of spatial audio location and content using convolutional neural networks    Hirvonen    2015        https://www.researchgate.net/profile/Toni_Hirvonen/publication/276061831_Classification_of_Spatial_Audio_Location_and_Content_Using_Convolutional_Neural_Networks/links/5550665908ae12808b37fe5a/Classification-of-Spatial-Audio-Location-and-Content-Using-Convolutional-Neural-Networks.pdf                                               
Deep learning, audio adversaries, and music content analysis    Kereliuk    2015        http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6905/pdf/imm6905.pdf                                               
Deep Learning and Music Adversaries Kereliuk    2015    IEEE_TMM    http://ieeexplore.ieee.org/document/7254179/    https://github.com/coreyker/dnn-mgr     CNN     Magnitude spectral frames   4           Genre   GTzan & LMD     
A software framework for musical data augmentation  McFee   2015        https://bmcfee.github.io/papers/ismir2015_augmentation.pdf                      4           Instrument detection    MedleyDB    precise description architecture    
A deep bag-of-features model for music auto-tagging Nam 2015        https://arxiv.org/pdf/1508.04999v1.pdf                                              
Environmental sound classification with convolutional neural networks   Piczak  2015        https://scholar.google.co.kr/scholar?hl=en&q=Environmental+sound+classification+with+convolutional+neural+networks&btnG=&as_sdt=1%2C5&as_sdtp=                                              
Exploring data augmentation for improved singing voice detection with neural networks   Schlueter   2015    ISMIR   https://grrrr.org/pub/schlueter-2015-ismir.pdf  https://github.com/f0k/ismir2015    No  CNN     Spectrogram             SVD Inhouse & Jamendo & RWC     
Singer traits identification using deep neural network  Shi 2015    Report  https://cs224d.stanford.edu/reports/SkiZhengshan.pdf    No  No                                      
Folk music style modelling by recurrent neural networks with long short term memory units   Sturm   2015    ISMIR   http://ismir2015.uma.es/LBD/LBD13.pdf   https://github.com/IraKorshunova/folk-rnn                               Composition         
A deep neural network for modeling music    Zhang   2015                         VQ w/ K-means, then 1D convolution              Semantic modelling (Genre prediction)           
"The munich LSTM-RNN approach to the mediaeval 2014 ""emotion in music"" task"  Coutinho    2014        https://pdfs.semanticscholar.org/8a24/c5131d5a28165f719697028c34b00e6d3f60.pdf          LSTM-RNN                        MER         
Deep learning for music genre classification    Feng    2014        https://courses.engr.illinois.edu/ece544na/fa2014/Tao_Feng.pdf  No  No              5           Genre   GTzan   technical report    
Recognition of acoustic events using deep neural networks   Gencoglu    2014        https://www.cs.tut.fi/sgn/arg/music/tuomasv/dnn_eusipco2014.pdf                                             
Improving content-based and hybrid music recommendation using deep learning Wang    2014        http://www.smcnus.org/wp-content/uploads/2014/08/reco_MM14.pdf                                              
Moving beyond feature design: deep architectures and automatic feature learning in music informatics    Humphrey    2012        http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.2304&rep=rep1&type=pdf                                             
Rethinking automatic chord recognition with convolutional neural networks   Korzeniowski    2012    ICMLA   http://ieeexplore.ieee.org/abstract/document/6406762/   No  No  CNN                     Chord recognition           
Learning sparse feature representations for music annotation and retrieval  Nam 2012    ISMIR   https://pdfs.semanticscholar.org/099d/85f25e9336f48ff64287a4b53ee5fb64ab51.pdf  No  No                                      
Audio-based music classification with a pretrained convolutional network    Dieleman    2011    ISMIR   http://www.ismir2011.ismir.net/papers/PS6-3.pdf                                             
A convolutional-kernel based approach for note onset detection in piano-solo audio signals  Nava    2004        http://www.murase.nuie.nagoya-u.ac.jp/~ide/res/paper/E04-conference-pablo-1.pdf                                             
A supervised learning approach to musical style recognition Buzzanca    2002        https://www.researchgate.net/profile/Giuseppe_Buzzanca/publication/228588086_A_supervised_learning_approach_to_musical_style_recognition/links/54b43ee90cf26833efd0109f.pdf                                             
replace arxiv with unpublished
